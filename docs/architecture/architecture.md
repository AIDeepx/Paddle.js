## 技术方案全景

Paddle.js包含离线模块和在线模块，离线模块负责线下模型处理，在线部分主要负责神经网络计算推理。

#### 离线模块
用户在拿到模型之后，首先进行模型处理。因为在浏览器中需要使用到浏览器友好的模型格式，用户可通过 Paddle.js 提供的模型工具链对模型格式进行转换和离线优化。通过算子融合等手段初步进行模型优化处理，减少模型体积。用户也可贡献模型至官网。


#### 在线推理模块

在模型处理完成之后会进行到在线推理模块。用户需选取一个计算方案，调用CPU或GPU算力，进行计算加速。Paddle.js 目前支持 WebGL、WebGPU、WASM、Plain JS 及 NodeGL backend，用户可根据自己的模型及落地场景选择合适的计算方案。

首先是初始化过程，加载用户处理后的模型并生成神经网络拓扑图；算子生成器根据用户注册的计算方案，将神经网络每一层算子生成对应的可执行单元。引擎会默认执行预热过程，传递与模型输入 shape 相同的 tensor —— 全 1 的二进制浮点数据，并在神经网络中完成推理计算，在预热过程中完成权重上传和数据缓存，以便加速真实用户数据的推理计算过程。

在完成模型加载及初始化之后，用户将数据上传，Paddle.js 目前支持的用户输入包括图片及视频流，需要对用户输入模型前处理，包含对图像进行 resize、像素填充、数据归一化等操作，将用户输入转换成二进制浮点数据，转换成符合模型要求的输入 tensor。

下一步进行神经网络推理计算，在用户注册的 backend 环境通过神经网络层层计算得出推理结果，最后进行模型后处理。用户可使用 paddlejs-mediapipe 工具更加快速便捷的进行前后处理。

Paddle.js 同时提供封装好的模型工程库，通过 paddlejs-models 模块使用简易API快速进行场景落地。如需性能数据，也可使用 paddlejs-benchmark 性能工具，产出 benchmark 报告，评估模型及算子的推理耗时。

Paddle.js 代码深度精简，采用了多种技术手段针对神经网络执行效率和算子计算性能进行了系统性的优化，保证达到在浏览器上实时执行效果流畅无卡顿。

<p align="center"><img width="774" alt="arch" src="https://user-images.githubusercontent.com/76191671/125030616-f774cd80-e0bd-11eb-948d-b03fef99a0e9.png"></p>